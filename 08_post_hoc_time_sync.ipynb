{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 08 - Frame Extraction and Gaze Visualization\n",
    "\n",
    "Pupil Core distinguishes between `System Time` and `Pupil Time`, measured in seconds.\n",
    "\n",
    "`System Time` is the current time of the device running Pupil Core software and uses the Unix epoc, while `Pupil Time` has an arbitrary that can be used to synchronize the clock between multiple devices.\n",
    "\n",
    "Since the exported data (pupil, gaze, fixations, blinks, surface, etc.) uses timestamps in `Pupil Time`, it is often desireable to convert these timestamps into Unix timestamps (`System Time`), or into `datetime` objects in Python.\n",
    "\n",
    "This tutorial shows how to easily perform the conversion and save the data in a new file.\n",
    "\n",
    "---\n",
    "\n",
    "> To execute this notebook, download the [sample recording](https://drive.google.com/file/d/1vzjZkjoi8kESw8lBnsa_k_8hXPf3fMMC/view?usp=sharing). Unzip and move it into the `recordings` directory for this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:}'.format\n",
    "\n",
    "DATAFRAME_HEAD_COUNT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the path to the recording directory, as well as the export directory within the recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_dir = pathlib.Path(\".\").joinpath(\"recordings\").joinpath(\"sample_recording_v2\").absolute()\n",
    "assert rec_dir.is_dir(), \"Please download the sample recording into 'recordings' directory.\"\n",
    "rec_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = rec_dir.joinpath(\"exports\").joinpath(\"000\")\n",
    "assert export_dir.is_dir(), \"Please create at least one export.\"\n",
    "export_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recording contains a meta-data file (`info.player.json`) which provide essential information about the recording itself, as well as the context in which it was made. More information about the format can be found [here](https://github.com/pupil-labs/pupil/blob/master/pupil_src/shared_modules/pupil_recording/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rec_dir.joinpath(\"info.player.json\").open() as file:\n",
    "    meta_info = json.load(file)\n",
    "\n",
    "meta_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the start time of the recording in `System Time` (`start_time_system_s` field) and in `Pupil Time` (`start_time_synced_s` field), we calculate the offset which will be applied to timestamps in other data files to convert them to Unix timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timestamp_unix = meta_info[\"start_time_system_s\"]\n",
    "start_timestamp_pupil = meta_info[\"start_time_synced_s\"]\n",
    "start_timestamp_diff = start_timestamp_unix - start_timestamp_pupil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pupil Positions Timestamps\n",
    "\n",
    "The code bellow implements the following steps:\n",
    "- Load the `pupil_positions.csv` file from the export directory into a Pandas dataframe\n",
    "- Convert the `pupil_timestamp` column values to Unix timestamps (new `pupil_timestamp_unix` column)\n",
    "- Convert the `pupil_timestamp` column values to datetime objects (new `pupil_timestamp_datetime` column)\n",
    "- Save the updated dataframe into `pupil_positions_unix_datetime` file in the export directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_positions_df = pd.read_csv(export_dir.joinpath(\"pupil_positions.csv\"))\n",
    "pupil_positions_df.head(DATAFRAME_HEAD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_positions_df[\"pupil_timestamp_unix\"] = pupil_positions_df[\"pupil_timestamp\"] + start_timestamp_diff\n",
    "pupil_positions_df.head(DATAFRAME_HEAD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_positions_df[\"pupil_timestamp_datetime\"] = pd.to_datetime(pupil_positions_df[\"pupil_timestamp_unix\"], unit=\"s\")\n",
    "pupil_positions_df.head(DATAFRAME_HEAD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_positions_df.to_csv(export_dir.joinpath(\"pupil_positions_unix_datetime.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow, the same steps are used to convert and save Unix and datetime timestamps for gaze and fixation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaze Positions Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_positions_df = pd.read_csv(export_dir.joinpath(\"gaze_positions.csv\"))\n",
    "gaze_positions_df[\"gaze_timestamp_unix\"] = gaze_positions_df[\"gaze_timestamp\"] + start_timestamp_diff\n",
    "gaze_positions_df[\"gaze_timestamp_datetime\"] = pd.to_datetime(gaze_positions_df[\"gaze_timestamp_unix\"], unit=\"s\")\n",
    "gaze_positions_df.to_csv(export_dir.joinpath(\"gaze_positions_unix_datetime.csv\"))\n",
    "gaze_positions_df.head(DATAFRAME_HEAD_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixations Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_df = pd.read_csv(export_dir.joinpath(\"fixations.csv\"))\n",
    "fixations_df[\"start_timestamp_unix\"] = fixations_df[\"start_timestamp\"] + start_timestamp_diff\n",
    "fixations_df[\"start_timestamp_datetime\"] = pd.to_datetime(fixations_df[\"start_timestamp_unix\"], unit=\"s\")\n",
    "fixations_df.to_csv(export_dir.joinpath(\"fixations_unix_datetime.csv\"))\n",
    "fixations_df.head(DATAFRAME_HEAD_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surfaces Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaces_dir = export_dir.joinpath(\"surfaces\")\n",
    "assert surfaces_dir.is_dir(), \"Please add at least one surface to the export.\"\n",
    "surfaces_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aid in converting multiple files, some of which have more than one column with timestamp values, the `convert_and_save_timestamps` function is defined bellow, which replicates the steps previously described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_save_timestamps(input_path, column_names, timestamp_offset=start_timestamp_diff):\n",
    "    \n",
    "    output_path = input_path.with_name(input_path.stem + \"_unix_datetime\").with_suffix(input_path.suffix)\n",
    "\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    for column_name in column_names:\n",
    "        unix_column_name = column_name + \"_unix\"\n",
    "        datetime_column_name = column_name + \"_datetime\"\n",
    "\n",
    "        df[unix_column_name] = df[column_name] + timestamp_offset\n",
    "        df[datetime_column_name] = pd.to_datetime(df[unix_column_name], unit=\"s\")\n",
    "\n",
    "    df.to_csv(output_path)\n",
    "\n",
    "    return df.head(DATAFRAME_HEAD_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_and_save_timestamps(\n",
    "    input_path=surfaces_dir.joinpath(\"surface_events.csv\"),\n",
    "    column_names=[\"world_timestamp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_and_save_timestamps(\n",
    "    input_path=surfaces_dir.joinpath(\"surf_positions_Cover.csv\"),\n",
    "    column_names=[\"world_timestamp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_and_save_timestamps(\n",
    "    input_path=surfaces_dir.joinpath(\"gaze_positions_on_surface_Cover.csv\"),\n",
    "    column_names=[\"world_timestamp\", \"gaze_timestamp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_and_save_timestamps(\n",
    "    input_path=surfaces_dir.joinpath(\"fixations_on_surface_Cover.csv\"),\n",
    "    column_names=[\"world_timestamp\", \"start_timestamp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
