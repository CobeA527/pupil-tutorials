{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 07 - Frame Extraction and Gaze Visualization\n",
    "\n",
    "In this tutorial we will look at how to extract individual frame images from the world video using `ffmpeg`, and visualize gaze positions for a specific frame.\n",
    "\n",
    "1. Extract all frame images from the world video\n",
    "1. Load exported gaze positions using `Pandas`\n",
    "1. Visualize image and gaze positions for a frame index\n",
    "\n",
    "---\n",
    "> To execute this notebook, download the [sample recording](https://drive.google.com/file/d/1vzjZkjoi8kESw8lBnsa_k_8hXPf3fMMC/view?usp=sharing). Unzip and move it into the `recordings` directory for this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_dir = Path().joinpath(\"recordings\", \"sample_recording_v2\").resolve()\n",
    "assert rec_dir.is_dir(), f\"Please download the sample_recording_v2 into recordings/\"\n",
    "rec_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Frames\n",
    "\n",
    "Most video files generated by Pupil will have a variable frame rate, mirroring the exact frame rate of the incoming frames from the cameras.\n",
    "A common postprocessing step is extracting every frame from the videos.\n",
    "You can use a tool like [FFmpeg](https://ffmpeg.org/) for this, but need to keep in mind the variable frame rate.\n",
    "E.g. for extracting every frame from an exported world video, you can use:\n",
    "```\n",
    "ffmpeg -i \"/path/to/input/recording/world.mp4\" -vsync 0 \"/path/to/output/images/frame%06d.png\"\n",
    "```\n",
    "where the `-vsync 0` option ensures correct handling of the variable frame rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete previously extracted frames\n",
    "!rm -f ./data/extracted_frames/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual frames from the world video\n",
    "!ffmpeg -i \"./recordings/sample_recording_v2/world.mp4\" -vsync 0 \"./data/extracted_frames/frame%06d.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Gaze Data\n",
    "\n",
    "The sample recording contains an export with `gaze_positions.csv` file; we're using `Pandas` to read the data into a data frame for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze = pd.read_csv(\n",
    "    rec_dir.joinpath(\"exports\", \"000\", \"gaze_positions.csv\")\n",
    ")\n",
    "gaze.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Image and Gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_INDEX = 1601  # Frame index used for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the data of the extracted frame image with the given index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the extracted frame image path for the given index\n",
    "frame_index_path = Path().resolve()\n",
    "# Append path to extracted frame directory\n",
    "frame_index_path = frame_index_path.joinpath(\"data\", \"extracted_frames\")\n",
    "# File name matching the \"frame%06d.png\" template\n",
    "frame_index_path = frame_index_path.joinpath(f\"frame{str(FRAME_INDEX).rjust(6, '0')}.png\")\n",
    "assert frame_index_path.is_file(), f\"Can't find frame image at path: {frame_index_path}\"\n",
    "\n",
    "# Note that matplotlib's origin is by default in the top-left,\n",
    "# but Pupil's data is in the bottom-left, so we flip the image and\n",
    "# use a different origin when calling `imshow()`\n",
    "frame_index_image = plt.imread(frame_index_path)\n",
    "frame_index_image = np.flipud(frame_index_image)\n",
    "\n",
    "frame_index_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the gaze points for the give frame index into an array of `(x, y)` normalized coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the array of normalized gaze points for the given index\n",
    "gaze_points = gaze[gaze[\"world_index\"] == FRAME_INDEX]\n",
    "gaze_points = gaze_points.sort_values(by=\"gaze_timestamp\")\n",
    "gaze_points = gaze_points[[\"norm_pos_x\", \"norm_pos_y\"]]\n",
    "gaze_points = gaze_points.to_numpy()\n",
    "gaze_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the gaze points data into the `x` and `y` component arrays, and denormalize it to the size of the frame image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split gaze points into separate X and Y coordinate arrays\n",
    "X, Y = gaze_points[:, 0], gaze_points[:, 1]\n",
    "\n",
    "# Denormalize gaze points within the frame\n",
    "H, W = frame_index_image.shape[:-1]\n",
    "X, Y = X * W, Y * H\n",
    "\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's time to plot the image and overlay the gaze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting configuration\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.title(f\"Frame #{FRAME_INDEX}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Draw the frame image\n",
    "plt.imshow(frame_index_image, origin=\"lower\")\n",
    "\n",
    "# Draw the gaze points for the given frame\n",
    "plt.scatter(X, Y, color=(0.0, 0.7, 0.25), zorder=1, s=700, alpha=0.2)\n",
    "\n",
    "# Draw the gaze movement line for the given frame\n",
    "plt.plot(X, Y, color=(1.0, 0.0, 0.4), zorder=2, lw=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
